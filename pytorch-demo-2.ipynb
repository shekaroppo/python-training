{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f9b5b4-806f-42a3-ad4a-6a139ff22d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7006ee3-7002-4182-affa-47cf3741fa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 26421880/26421880 [00:45<00:00, 584596.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 29515/29515 [00:00<00:00, 2177762.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4422102/4422102 [00:00<00:00, 7000319.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 5148/5148 [00:00<00:00, 837624.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31b9e3c-19c9-4cd3-b4eb-23866d0cc5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9696748f-2617-4f74-8d57-d8fefae12b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5692ee-7707-423e-8294-fe4aeb9f0298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34172a4-7d01-4ceb-8ed6-335966de0998",
   "metadata": {},
   "source": [
    "## hyper parameters\n",
    "\n",
    "1. learning rate\n",
    "2. batch size\n",
    "3. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8111d6dd-677e-496d-bded-b38cba5feca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f02df4f-760c-4df0-982c-920a0f64ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a55ea1-8a31-462c-96fb-5a5edd06e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b3b8f72-cc83-41f8-9338-c563e608fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.644702  [   64/60000]\n",
      "loss: 0.751833  [ 6464/60000]\n",
      "loss: 0.511851  [12864/60000]\n",
      "loss: 0.748379  [19264/60000]\n",
      "loss: 0.653811  [25664/60000]\n",
      "loss: 0.654924  [32064/60000]\n",
      "loss: 0.709898  [38464/60000]\n",
      "loss: 0.724046  [44864/60000]\n",
      "loss: 0.713456  [51264/60000]\n",
      "loss: 0.664739  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.671599 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.623542  [   64/60000]\n",
      "loss: 0.732549  [ 6464/60000]\n",
      "loss: 0.495344  [12864/60000]\n",
      "loss: 0.734941  [19264/60000]\n",
      "loss: 0.642383  [25664/60000]\n",
      "loss: 0.643174  [32064/60000]\n",
      "loss: 0.692229  [38464/60000]\n",
      "loss: 0.713906  [44864/60000]\n",
      "loss: 0.701100  [51264/60000]\n",
      "loss: 0.650708  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.657759 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.604427  [   64/60000]\n",
      "loss: 0.714624  [ 6464/60000]\n",
      "loss: 0.480487  [12864/60000]\n",
      "loss: 0.722460  [19264/60000]\n",
      "loss: 0.632064  [25664/60000]\n",
      "loss: 0.632694  [32064/60000]\n",
      "loss: 0.675652  [38464/60000]\n",
      "loss: 0.704819  [44864/60000]\n",
      "loss: 0.690216  [51264/60000]\n",
      "loss: 0.637576  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.644941 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.587056  [   64/60000]\n",
      "loss: 0.697954  [ 6464/60000]\n",
      "loss: 0.467026  [12864/60000]\n",
      "loss: 0.710778  [19264/60000]\n",
      "loss: 0.622750  [25664/60000]\n",
      "loss: 0.623408  [32064/60000]\n",
      "loss: 0.660152  [38464/60000]\n",
      "loss: 0.696805  [44864/60000]\n",
      "loss: 0.680710  [51264/60000]\n",
      "loss: 0.625163  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.633052 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.571170  [   64/60000]\n",
      "loss: 0.682484  [ 6464/60000]\n",
      "loss: 0.454638  [12864/60000]\n",
      "loss: 0.699875  [19264/60000]\n",
      "loss: 0.614309  [25664/60000]\n",
      "loss: 0.615132  [32064/60000]\n",
      "loss: 0.645744  [38464/60000]\n",
      "loss: 0.689731  [44864/60000]\n",
      "loss: 0.672493  [51264/60000]\n",
      "loss: 0.613341  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.622081 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.556664  [   64/60000]\n",
      "loss: 0.668166  [ 6464/60000]\n",
      "loss: 0.443446  [12864/60000]\n",
      "loss: 0.689611  [19264/60000]\n",
      "loss: 0.606358  [25664/60000]\n",
      "loss: 0.607640  [32064/60000]\n",
      "loss: 0.632282  [38464/60000]\n",
      "loss: 0.683691  [44864/60000]\n",
      "loss: 0.665390  [51264/60000]\n",
      "loss: 0.602090  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.611948 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.543282  [   64/60000]\n",
      "loss: 0.654859  [ 6464/60000]\n",
      "loss: 0.433107  [12864/60000]\n",
      "loss: 0.679979  [19264/60000]\n",
      "loss: 0.598915  [25664/60000]\n",
      "loss: 0.600747  [32064/60000]\n",
      "loss: 0.619719  [38464/60000]\n",
      "loss: 0.678607  [44864/60000]\n",
      "loss: 0.659315  [51264/60000]\n",
      "loss: 0.591342  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.602581 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.530884  [   64/60000]\n",
      "loss: 0.642527  [ 6464/60000]\n",
      "loss: 0.423514  [12864/60000]\n",
      "loss: 0.670873  [19264/60000]\n",
      "loss: 0.591942  [25664/60000]\n",
      "loss: 0.594355  [32064/60000]\n",
      "loss: 0.608005  [38464/60000]\n",
      "loss: 0.674363  [44864/60000]\n",
      "loss: 0.654138  [51264/60000]\n",
      "loss: 0.581091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.593917 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.519447  [   64/60000]\n",
      "loss: 0.631076  [ 6464/60000]\n",
      "loss: 0.414640  [12864/60000]\n",
      "loss: 0.662261  [19264/60000]\n",
      "loss: 0.585219  [25664/60000]\n",
      "loss: 0.588408  [32064/60000]\n",
      "loss: 0.597222  [38464/60000]\n",
      "loss: 0.670947  [44864/60000]\n",
      "loss: 0.649660  [51264/60000]\n",
      "loss: 0.571289  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.585905 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.508749  [   64/60000]\n",
      "loss: 0.620486  [ 6464/60000]\n",
      "loss: 0.406404  [12864/60000]\n",
      "loss: 0.654062  [19264/60000]\n",
      "loss: 0.578791  [25664/60000]\n",
      "loss: 0.582808  [32064/60000]\n",
      "loss: 0.587237  [38464/60000]\n",
      "loss: 0.668271  [44864/60000]\n",
      "loss: 0.645840  [51264/60000]\n",
      "loss: 0.561845  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.578483 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.498721  [   64/60000]\n",
      "loss: 0.610655  [ 6464/60000]\n",
      "loss: 0.398729  [12864/60000]\n",
      "loss: 0.646257  [19264/60000]\n",
      "loss: 0.572636  [25664/60000]\n",
      "loss: 0.577405  [32064/60000]\n",
      "loss: 0.578036  [38464/60000]\n",
      "loss: 0.666228  [44864/60000]\n",
      "loss: 0.642557  [51264/60000]\n",
      "loss: 0.552780  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.571602 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.489323  [   64/60000]\n",
      "loss: 0.601528  [ 6464/60000]\n",
      "loss: 0.391589  [12864/60000]\n",
      "loss: 0.638871  [19264/60000]\n",
      "loss: 0.566599  [25664/60000]\n",
      "loss: 0.572111  [32064/60000]\n",
      "loss: 0.569517  [38464/60000]\n",
      "loss: 0.664731  [44864/60000]\n",
      "loss: 0.639738  [51264/60000]\n",
      "loss: 0.544021  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.565216 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.480485  [   64/60000]\n",
      "loss: 0.593071  [ 6464/60000]\n",
      "loss: 0.384899  [12864/60000]\n",
      "loss: 0.631845  [19264/60000]\n",
      "loss: 0.560626  [25664/60000]\n",
      "loss: 0.566955  [32064/60000]\n",
      "loss: 0.561590  [38464/60000]\n",
      "loss: 0.663704  [44864/60000]\n",
      "loss: 0.637335  [51264/60000]\n",
      "loss: 0.535516  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.559281 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.472061  [   64/60000]\n",
      "loss: 0.585238  [ 6464/60000]\n",
      "loss: 0.378627  [12864/60000]\n",
      "loss: 0.625113  [19264/60000]\n",
      "loss: 0.554705  [25664/60000]\n",
      "loss: 0.561902  [32064/60000]\n",
      "loss: 0.554234  [38464/60000]\n",
      "loss: 0.663060  [44864/60000]\n",
      "loss: 0.635215  [51264/60000]\n",
      "loss: 0.527291  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.553759 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.464092  [   64/60000]\n",
      "loss: 0.577986  [ 6464/60000]\n",
      "loss: 0.372749  [12864/60000]\n",
      "loss: 0.618651  [19264/60000]\n",
      "loss: 0.548813  [25664/60000]\n",
      "loss: 0.556949  [32064/60000]\n",
      "loss: 0.547426  [38464/60000]\n",
      "loss: 0.662774  [44864/60000]\n",
      "loss: 0.633276  [51264/60000]\n",
      "loss: 0.519331  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.548614 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.456545  [   64/60000]\n",
      "loss: 0.571276  [ 6464/60000]\n",
      "loss: 0.367232  [12864/60000]\n",
      "loss: 0.612442  [19264/60000]\n",
      "loss: 0.543020  [25664/60000]\n",
      "loss: 0.552017  [32064/60000]\n",
      "loss: 0.541091  [38464/60000]\n",
      "loss: 0.662701  [44864/60000]\n",
      "loss: 0.631489  [51264/60000]\n",
      "loss: 0.511642  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.543811 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.449377  [   64/60000]\n",
      "loss: 0.565021  [ 6464/60000]\n",
      "loss: 0.362037  [12864/60000]\n",
      "loss: 0.606485  [19264/60000]\n",
      "loss: 0.537333  [25664/60000]\n",
      "loss: 0.547068  [32064/60000]\n",
      "loss: 0.535155  [38464/60000]\n",
      "loss: 0.662797  [44864/60000]\n",
      "loss: 0.629841  [51264/60000]\n",
      "loss: 0.504220  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.539321 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.442546  [   64/60000]\n",
      "loss: 0.559190  [ 6464/60000]\n",
      "loss: 0.357163  [12864/60000]\n",
      "loss: 0.600705  [19264/60000]\n",
      "loss: 0.531762  [25664/60000]\n",
      "loss: 0.542237  [32064/60000]\n",
      "loss: 0.529626  [38464/60000]\n",
      "loss: 0.662974  [44864/60000]\n",
      "loss: 0.628252  [51264/60000]\n",
      "loss: 0.497132  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.535114 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.436030  [   64/60000]\n",
      "loss: 0.553759  [ 6464/60000]\n",
      "loss: 0.352606  [12864/60000]\n",
      "loss: 0.595090  [19264/60000]\n",
      "loss: 0.526295  [25664/60000]\n",
      "loss: 0.537504  [32064/60000]\n",
      "loss: 0.524432  [38464/60000]\n",
      "loss: 0.663188  [44864/60000]\n",
      "loss: 0.626716  [51264/60000]\n",
      "loss: 0.490334  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.531166 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.429841  [   64/60000]\n",
      "loss: 0.548671  [ 6464/60000]\n",
      "loss: 0.348324  [12864/60000]\n",
      "loss: 0.589661  [19264/60000]\n",
      "loss: 0.520959  [25664/60000]\n",
      "loss: 0.532813  [32064/60000]\n",
      "loss: 0.519588  [38464/60000]\n",
      "loss: 0.663444  [44864/60000]\n",
      "loss: 0.625195  [51264/60000]\n",
      "loss: 0.483836  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.527451 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.423917  [   64/60000]\n",
      "loss: 0.543901  [ 6464/60000]\n",
      "loss: 0.344271  [12864/60000]\n",
      "loss: 0.584438  [19264/60000]\n",
      "loss: 0.515745  [25664/60000]\n",
      "loss: 0.528155  [32064/60000]\n",
      "loss: 0.515057  [38464/60000]\n",
      "loss: 0.663741  [44864/60000]\n",
      "loss: 0.623705  [51264/60000]\n",
      "loss: 0.477605  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.523950 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.418238  [   64/60000]\n",
      "loss: 0.539411  [ 6464/60000]\n",
      "loss: 0.340433  [12864/60000]\n",
      "loss: 0.579405  [19264/60000]\n",
      "loss: 0.510645  [25664/60000]\n",
      "loss: 0.523535  [32064/60000]\n",
      "loss: 0.510812  [38464/60000]\n",
      "loss: 0.663985  [44864/60000]\n",
      "loss: 0.622182  [51264/60000]\n",
      "loss: 0.471636  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.520646 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.412804  [   64/60000]\n",
      "loss: 0.535225  [ 6464/60000]\n",
      "loss: 0.336785  [12864/60000]\n",
      "loss: 0.574548  [19264/60000]\n",
      "loss: 0.505695  [25664/60000]\n",
      "loss: 0.519000  [32064/60000]\n",
      "loss: 0.506791  [38464/60000]\n",
      "loss: 0.664164  [44864/60000]\n",
      "loss: 0.620634  [51264/60000]\n",
      "loss: 0.465987  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.517520 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.407566  [   64/60000]\n",
      "loss: 0.531292  [ 6464/60000]\n",
      "loss: 0.333311  [12864/60000]\n",
      "loss: 0.569889  [19264/60000]\n",
      "loss: 0.500844  [25664/60000]\n",
      "loss: 0.514592  [32064/60000]\n",
      "loss: 0.502996  [38464/60000]\n",
      "loss: 0.664234  [44864/60000]\n",
      "loss: 0.619087  [51264/60000]\n",
      "loss: 0.460602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.514557 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.402490  [   64/60000]\n",
      "loss: 0.527585  [ 6464/60000]\n",
      "loss: 0.330021  [12864/60000]\n",
      "loss: 0.565409  [19264/60000]\n",
      "loss: 0.496121  [25664/60000]\n",
      "loss: 0.510309  [32064/60000]\n",
      "loss: 0.499385  [38464/60000]\n",
      "loss: 0.664214  [44864/60000]\n",
      "loss: 0.617475  [51264/60000]\n",
      "loss: 0.455524  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.511741 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b34c6c1-5717-49bb-97ce-71f2b04683c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c8ddf1a-f32f-4e54-8c56-3ded9084a1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r6/24ltpybn28143j8xgwd6ghk40000gn/T/ipykernel_23613/863263723.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(\"model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = NeuralNetwork().to(device)\n",
    "loaded_model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b7a045f-d876-4a7c-945f-e0320235681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0105, -0.0251,  0.0024,  ...,  0.0296,  0.0313, -0.0357],\n",
      "        [ 0.0007, -0.0324, -0.0159,  ..., -0.0300,  0.0266,  0.0076]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0282,  0.0053], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0239,  0.0098,  0.0307,  ...,  0.0285, -0.0023,  0.0410],\n",
      "        [-0.0105, -0.0125, -0.0001,  ...,  0.0422, -0.0289,  0.0268]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0278, -0.0455], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0200,  0.0450,  0.0402,  ..., -0.0441, -0.0582, -0.0526],\n",
      "        [-0.0128, -0.0239,  0.0494,  ...,  0.0136, -0.0338, -0.0664]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0109,  0.0492], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {loaded_model}\\n\\n\")\n",
    "\n",
    "for name, param in loaded_model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c540fb3f-1049-4ff8-ac7c-0e4e48b3a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2df1d07-0f83-406a-8dea-e0aa27db53d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Ankle Boot\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "# Display image and label.\n",
    "features, labels = next(iter(test_dataloader))\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "img = features[0].squeeze()\n",
    "label = labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "# print(f\"Label: {label}\")\n",
    "print(f\"Label: {labels_map[label.item()]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
